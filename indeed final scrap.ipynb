{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25c7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_url(position, location):\n",
    "    \"\"\"Generate url from position and location\"\"\"\n",
    "    template = 'https://in.indeed.com/jobs?q={}&l={}'\n",
    "    position = position.replace(' ', '%20')\n",
    "    location = location.replace(' ', '+')\n",
    "    url = template.format(position, location)\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    \n",
    "    job_title = card.find('h2',{'class':'jobTitle'}).text\n",
    "    #company = card.find('a').text\n",
    "    job_location = card.find('div',{'class':'companyLocation'}).text\n",
    "    post_date = card.find('span', 'date').text\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    summary = card.find('li').text\n",
    "    #job_url = 'https://www.indeed.com' + card.h2.a.get('href')\n",
    "\n",
    "    # this does not exists for all jobs, so handle the exceptions\n",
    "    try:\n",
    "        job_salary=card.find('div',{'class':'metadata salary-snippet-container'}).text\n",
    "    except AttributeError:\n",
    "        job_salary=''\n",
    "    try:\n",
    "        company = card.find('a').text\n",
    "    except AttributeError:\n",
    "        company=card.find('span',{'class':'companyName'}).text ## somewhere tag is different\n",
    "        \n",
    "    record = (job_title, company, job_location, post_date, today, summary, job_salary)\n",
    "    return record\n",
    "\n",
    "\n",
    "def main(position, location):\n",
    "    \"\"\"Run the main program routine\"\"\"\n",
    "    records = []\n",
    "    url = get_url(position, location)\n",
    "    \n",
    "    # extract the job data\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        cards = soup.find_all('div', 'job_seen_beacon')\n",
    "        for card in cards:\n",
    "            record = get_record(card)\n",
    "            records.append(record)\n",
    "        try:\n",
    "            url = 'https://in.indeed.com' + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "        except AttributeError:\n",
    "            break\n",
    "    with open('resultsindeed.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['JobTitle', 'Company', 'Location', 'PostDate', 'ExtractDate', 'Summary', 'Salary'])\n",
    "        writer.writerows(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225ba7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('data scientist', 'india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c162942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397a5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/hp/Downloads/Imarticus/Python/resultsindeed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216d22bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobTitle</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>PostDate</th>\n",
       "      <th>ExtractDate</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product: Data Scientist</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Hyderabad, Telangana</td>\n",
       "      <td>Posted30+ days ago</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>Proactively research data and identify opportu...</td>\n",
       "      <td>₹34,20,000 - ₹51,40,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist (BE/ B-tech 4-6 yrs)</td>\n",
       "      <td>CommerceIQ</td>\n",
       "      <td>Bengaluru, Karnataka•Temporarily Remote</td>\n",
       "      <td>Posted30+ days ago</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>Work on data science roadmap and build the cor...</td>\n",
       "      <td>₹25,00,000 - ₹35,00,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Hyderabad, Telangana</td>\n",
       "      <td>Posted30+ days ago</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>Proactively research data and identify opportu...</td>\n",
       "      <td>₹40,00,000 - ₹60,00,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>newAssociate Data Scientist</td>\n",
       "      <td>Shell</td>\n",
       "      <td>Bengaluru, Karnataka+1 location</td>\n",
       "      <td>PostedToday</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>Gathers data, analyses and reports findings.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist-CAI</td>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "      <td>Posted30+ days ago</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>Hands-on experience in data wrangling (ETL), f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              JobTitle     Company  \\\n",
       "0              Product: Data Scientist      Indeed   \n",
       "1  Data Scientist (BE/ B-tech 4-6 yrs)  CommerceIQ   \n",
       "2                Senior Data Scientist      Indeed   \n",
       "3          newAssociate Data Scientist       Shell   \n",
       "4                   Data Scientist-CAI   HDFC Bank   \n",
       "\n",
       "                                  Location            PostDate ExtractDate  \\\n",
       "0                     Hyderabad, Telangana  Posted30+ days ago  2022-01-25   \n",
       "1  Bengaluru, Karnataka•Temporarily Remote  Posted30+ days ago  2022-01-25   \n",
       "2                     Hyderabad, Telangana  Posted30+ days ago  2022-01-25   \n",
       "3          Bengaluru, Karnataka+1 location         PostedToday  2022-01-25   \n",
       "4                      Mumbai, Maharashtra  Posted30+ days ago  2022-01-25   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Proactively research data and identify opportu...   \n",
       "1  Work on data science roadmap and build the cor...   \n",
       "2  Proactively research data and identify opportu...   \n",
       "3       Gathers data, analyses and reports findings.   \n",
       "4  Hands-on experience in data wrangling (ETL), f...   \n",
       "\n",
       "                           Salary  \n",
       "0  ₹34,20,000 - ₹51,40,000 a year  \n",
       "1  ₹25,00,000 - ₹35,00,000 a year  \n",
       "2  ₹40,00,000 - ₹60,00,000 a year  \n",
       "3                             NaN  \n",
       "4                             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19402ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea03492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobTitle         0\n",
       "Company          0\n",
       "Location         0\n",
       "PostDate         0\n",
       "ExtractDate      0\n",
       "Summary          0\n",
       "Salary         909\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee33b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
